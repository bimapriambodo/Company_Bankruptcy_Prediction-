{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f437119-7e11-40b3-9476-82bf4ea4d570",
   "metadata": {},
   "source": [
    "# FLow Modelling for Preparing PY script\n",
    "\n",
    "notebook ini digunakan untuk eksperimentasi script sebelum dibawa ke bentuk script py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b203faf-740c-48c3-9431-b9e5b6a7e822",
   "metadata": {},
   "source": [
    "# 1. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "4a6a4895-05aa-4f61-a664-0470a7b35257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "7fa32524-57d2-4117-aedc-745e7e8cb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r\"../config/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "58af7dab-dbcd-41fd-8bcd-2a02dff2e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config()->dict:\n",
    "\n",
    "    '''\n",
    "    this function load the config.yaml file\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "    except FileNotFoundError as fe:\n",
    "        raise RuntimeError(\"Parameter File Not Found!\")\n",
    "\n",
    "    return config\n",
    "\n",
    "def load_pickle(file_path: str):\n",
    "\n",
    "    '''\n",
    "    handler function to load pickle file\n",
    "    '''\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            pick = joblib.load(f)\n",
    "\n",
    "    except FileNotFoundError as fe:\n",
    "        raise RuntimeError(\"Parameter File Not Found!\")\n",
    "\n",
    "    return pick\n",
    "\n",
    "def dump_pickle(file, file_path: str):\n",
    "\n",
    "    '''\n",
    "    handler function to dump pickle\n",
    "    '''\n",
    "\n",
    "    return joblib.dump(file, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "e341be05-e2e0-4d85-94f5-7fb67f510dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "a183e54b-6aba-4102-bffa-6b2a8cc3f49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': '../1_data/raw_data/5year.arff',\n",
       " 'raw_df_path': '../1_data/processed_data/raw_df.pkl',\n",
       " 'train_set_path': {'x_train': '../1_data/processed_data/x_train.pkl',\n",
       "  'y_train': '../1_data/processed_data/y_train.pkl'},\n",
       " 'test_set_path': {'x_test': '../1_data/processed_data/x_test.pkl',\n",
       "  'y_test': '../1_data/processed_data/y_test.pkl'},\n",
       " 'prep_rus_path': {'x_rus': '../1_data/processed_data/x_rus.pkl',\n",
       "  'y_rus': '../1_data/processed_data/y_rus.pkl'},\n",
       " 'prep_sm_path': {'x_sm': '../1_data/processed_data/x_sm.pkl',\n",
       "  'y_sm': '../1_data/processed_data/y_sm.pkl'},\n",
       " 'prep_test_path': {'x_test': '../1_data/processed_data/x_test_prep.pkl',\n",
       "  'y_test': '../1_data/processed_data/y_test.pkl'},\n",
       " 'production_model_path': '../4_models/model_prod.pkl',\n",
       " 'training_log_path': '../5_log/training_log.json',\n",
       " 'scaler_path': '../4_models/std_scaler_prod.pkl',\n",
       " 'float_columns': ['Attr21',\n",
       "  'Attr13',\n",
       "  'Attr27',\n",
       "  'Attr34',\n",
       "  'Attr24',\n",
       "  'Attr35',\n",
       "  'Attr51',\n",
       "  'Attr6',\n",
       "  'Attr56',\n",
       "  'Attr49',\n",
       "  'Attr40',\n",
       "  'Attr55',\n",
       "  'Attr50',\n",
       "  'Attr58',\n",
       "  'Attr43'],\n",
       " 'int64_columns': ['class'],\n",
       " 'predictors': ['Attr21',\n",
       "  'Attr13',\n",
       "  'Attr27',\n",
       "  'Attr34',\n",
       "  'Attr24',\n",
       "  'Attr35',\n",
       "  'Attr51',\n",
       "  'Attr6',\n",
       "  'Attr56',\n",
       "  'Attr49',\n",
       "  'Attr40',\n",
       "  'Attr55',\n",
       "  'Attr50',\n",
       "  'Attr58',\n",
       "  'Attr43'],\n",
       " 'label': ['class']}"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182e039-5e99-4b68-a999-0582ad44847a",
   "metadata": {},
   "source": [
    "# 2. Data Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "8571c05d-b56a-486a-8c87-113ef1d9819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "# from src.utils import load_config, dump_pickle\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "f8115fb3-b8c2-4291-b0b1-7553824802a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_df(raw_data_path: str):\n",
    "\n",
    "    df = arff.loadarff(raw_data_path)\n",
    "    df = pd.DataFrame(df[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "f3f96944-9ebd-4a8c-b5ef-06aec35eaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(dataframe: pd.DataFrame)->pd.DataFrame:\n",
    "    temp = copy.deepcopy(dataframe)\n",
    "    # temp.dropna(inplace=True)\n",
    "    temp['class'] = temp['class'].replace(\"b\",'')\n",
    "    temp['class'] = temp['class'].astype(int)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "214a59eb-1e6f-4574-b09b-3a30c7affca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataframe: pd.DataFrame) -> tuple:\n",
    "\n",
    "    df = copy.deepcopy(dataframe)\n",
    "\n",
    "    X = df.drop(columns=config[\"label\"])\n",
    "    y = df[config[\"label\"]]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "347d0b36-f781-48b7-b66a-4282b454b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation_selections(x_train: pd.DataFrame, x_test: pd.DataFrame)->pd.DataFrame:\n",
    "    x_train = copy.deepcopy(x_train)\n",
    "    x_test = copy.deepcopy(x_test)\n",
    "    \n",
    "    #select variables using modelling\n",
    "    x_train = x_train[config[\"predictors\"]]\n",
    "    x_test = x_test[config[\"predictors\"]]\n",
    "    \n",
    "    #handling missing values\n",
    "    x_train.fillna(-9999999999, inplace=True)\n",
    "    x_test.fillna(-9999999999, inplace=True)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "1521a26a-71be-4e66-90f1-13857e291682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_float(dataframe: pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    df = copy.deepcopy(dataframe)\n",
    "\n",
    "    df[config[\"float_columns\"]] = df[config[\"float_columns\"]].astype(\"float64\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "ad6d9b69-9356-486b-9384-98a181080036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Jalankan pipeline data collections\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    \n",
    "    df = read_raw_df(config[\"raw_dataset_path\"])\n",
    "    dump_pickle(df, config[\"raw_df_path\"])\n",
    "    df = cleansing(df)\n",
    "    x_train, x_test, y_train, y_test = split_data(df)\n",
    "    x_train, x_test = imputation_selections(x_train, x_test)\n",
    "    x_train = int_to_float(x_train)\n",
    "    x_test = int_to_float(x_test)\n",
    "    dump_pickle(x_train, config[\"train_set_path\"][\"x_train\"])\n",
    "    dump_pickle(y_train, config[\"train_set_path\"][\"y_train\"])\n",
    "    dump_pickle(x_test, config[\"test_set_path\"][\"x_test\"])\n",
    "    dump_pickle(y_test, config[\"test_set_path\"][\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "5ea84a4b-380c-42cf-9a68-8ed97fcf9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdf05f-7507-49a4-a2cc-668900e90d19",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "41596adb-1181-4185-81ac-2c748ab92f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import copy\n",
    "# from src.utils import load_config, load_pickle, dump_pickle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "4bd7f120-470e-48f0-87e6-4910ce07169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_scaler_fit(x_train: pd.DataFrame):\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "\n",
    "    std_scaler.fit(x_train)\n",
    "\n",
    "    return std_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "bd5a0dc6-e5fc-4565-97ca-7801c74fcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_scaler_transform(features: pd.DataFrame, scaler: object) -> pd.DataFrame:\n",
    "\n",
    "    '''\n",
    "    this function transform features using standar scaler machine\n",
    "    '''\n",
    "    \n",
    "    col_names = scaler.feature_names_in_\n",
    "\n",
    "    feat = copy.deepcopy(features)\n",
    "\n",
    "    scaled = scaler.transform(feat)\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled, columns=col_names)\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "d90780c9-f361-4d53-bdc0-4a9bf4a1677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rus_balancer(x_train, y_train):\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    x_rus, y_rus = rus.fit_resample(x_train, y_train)\n",
    "\n",
    "    return x_rus, y_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "1e7b6db5-df4f-450e-b71d-3258f6f1d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm_balancer(x_train, y_train):\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "\n",
    "    x_sm, y_sm = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "    return x_sm, y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "54ac44aa-21d2-4f76-a153-8f4c92464352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = load_config()\n",
    "\n",
    "    x_train = load_pickle(config[\"train_set_path\"][\"x_train\"])\n",
    "    x_test = load_pickle(config[\"test_set_path\"][\"x_test\"])\n",
    "\n",
    "    y_train = load_pickle(config[\"train_set_path\"][\"y_train\"])\n",
    "    y_test = load_pickle(config[\"test_set_path\"][\"y_test\"])\n",
    "    \n",
    "    # standardizing\n",
    "    scaler = std_scaler_fit(x_train)\n",
    "    dump_pickle(scaler, config[\"scaler_path\"])\n",
    "    x_train_scaled = std_scaler_transform(x_train, scaler)\n",
    "    x_test_scaled = std_scaler_transform(x_test, scaler)\n",
    "    # class balancer - rus\n",
    "    x_rus, y_rus = rus_balancer(x_train_scaled, y_train)\n",
    "    # class balancer - smote\n",
    "    x_sm, y_sm = sm_balancer(x_train_scaled, y_train)\n",
    "    # dump everything\n",
    "    dump_pickle(x_rus, config[\"prep_rus_path\"][\"x_rus\"])\n",
    "    dump_pickle(y_rus, config[\"prep_rus_path\"][\"y_rus\"])\n",
    "\n",
    "    dump_pickle(x_sm, config[\"prep_sm_path\"][\"x_sm\"])\n",
    "    dump_pickle(y_sm, config[\"prep_sm_path\"][\"y_sm\"])\n",
    "\n",
    "    dump_pickle(x_test_scaled, config[\"prep_test_path\"][\"x_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "c023e1d9-82d0-45c3-abe8-64ce6854c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b921132-bc99-4561-8c2c-abfb7bd65793",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "99127284-221f-4105-9736-4eca15867dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import hashlib\n",
    "\n",
    "# from src.utils import load_config, load_pickle, dump_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "bd5cebbf-41d9-4a1b-bb07-551ae8f01795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    return datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "8cb7224c-ddd1-42f8-8be8-c649a48deae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_template():\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"f1_score_avg\" : [],\n",
    "        \"precision_avg\" : [],\n",
    "        \"recall_avg\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "42f8f0ac-a76b-4932-93be-519ec5a86a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_updater(current_log, log_path):\n",
    "    current_log = current_log.copy()\n",
    "\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    except FileNotFoundError as ffe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    last_log.append(current_log)\n",
    "\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    return last_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "21add893-8235-43f2-bd12-ff4697d4fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(list_of_model, prefix_model_name, x_train, y_train, data_configuration_name, x_valid, y_valid, log_path):\n",
    "\n",
    "    list_of_model = copy.deepcopy(list_of_model)\n",
    "    logger = create_log_template()\n",
    "\n",
    "    for model in tqdm(list_of_model):    \n",
    "        model_name = prefix_model_name + \"-\" + model[\"model_name\"]\n",
    "\n",
    "        start_time = time_stamp()\n",
    "        model[\"model_object\"].fit(x_train, y_train)\n",
    "        finished_time = time_stamp()\n",
    "\n",
    "        elapsed_time = finished_time - start_time\n",
    "        elapsed_time = elapsed_time.total_seconds()\n",
    "\n",
    "        y_pred = model[\"model_object\"].predict(x_valid)\n",
    "        performance = classification_report(y_valid, y_pred, output_dict = True)\n",
    "\n",
    "        plain_id = str(start_time) + str(finished_time)\n",
    "        chiper_id = hashlib.md5(plain_id.encode()).hexdigest()\n",
    "\n",
    "        model[\"model_uid\"] = chiper_id\n",
    "\n",
    "        logger[\"model_name\"].append(model_name)\n",
    "        logger[\"model_uid\"].append(chiper_id)\n",
    "        logger[\"training_time\"].append(elapsed_time)\n",
    "        logger[\"training_date\"].append(str(start_time))\n",
    "        logger[\"performance\"].append(performance)\n",
    "        logger[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "        logger[\"precision_avg\"].append(performance[\"macro avg\"][\"precision\"])\n",
    "        logger[\"recall_avg\"].append(performance[\"macro avg\"][\"recall\"])\n",
    "        logger[\"data_configurations\"].append(data_configuration_name)\n",
    "\n",
    "    training_log = training_log_updater(logger, log_path)\n",
    "\n",
    "    return training_log, list_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "e3730d02-a056-444e-8faa-2839d5a62e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_to_df(training_log):\n",
    "    training_res = pd.DataFrame()\n",
    "\n",
    "    for log in tqdm(training_log):\n",
    "        training_res = pd.concat([training_res, pd.DataFrame(log)])\n",
    "    \n",
    "    training_res.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True], inplace = True)\n",
    "    training_res.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return training_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "171b249a-6f64-400d-80f0-28fc5258ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(training_log_df, list_of_model):\n",
    "    \"\"\"\n",
    "    Nah kalau fungsi ini buat milih model mana yang paling bagus, dan hasilnya buat production di api nantinya\n",
    "    \"\"\"\n",
    "    model_object = None\n",
    "\n",
    "    best_model_info = training_log_df.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True]).iloc[0]\n",
    "    i=0\n",
    "    for configuration_data in list_of_model:\n",
    "        for model_data in list_of_model[configuration_data]:\n",
    "            if model_data[\"model_uid\"] == best_model_info[\"model_uid\"]:\n",
    "                model_object = model_data[\"model_object\"]\n",
    "                break\n",
    "\n",
    "    if model_object == None:\n",
    "        model_object = load_pickle(config[\"production_model_path\"])\n",
    "        print(\"The best model not found in your list of model.\")\n",
    "    \n",
    "    return model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "b5a08de2-0355-4d50-93ca-3190354114bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = load_config()\n",
    "\n",
    "    # load preprocessed pickle of dataset\n",
    "    x_rus = load_pickle(config[\"prep_rus_path\"][\"x_rus\"])\n",
    "    y_rus = load_pickle(config[\"prep_rus_path\"][\"y_rus\"])\n",
    "\n",
    "    x_sm = load_pickle(config[\"prep_sm_path\"][\"x_sm\"])\n",
    "    y_sm = load_pickle(config[\"prep_sm_path\"][\"y_sm\"])\n",
    "\n",
    "    x_test = load_pickle(config[\"prep_test_path\"][\"x_test\"])\n",
    "    y_test = load_pickle(config[\"prep_test_path\"][\"y_test\"])\n",
    "    \n",
    "    # initiate models\n",
    "    lgr_baseline = LogisticRegression()\n",
    "    dct_baseline = DecisionTreeClassifier()\n",
    "    rfc_baseline = RandomForestClassifier()\n",
    "    knn_baseline = KNeighborsClassifier()\n",
    "    xgb_baseline = XGBClassifier(seed=42)\n",
    "    xgb_tuning = XGBClassifier(max_depth=6,\n",
    "                               min_child_weight=1,\n",
    "                               gamma=0.0,\n",
    "                               reg_alpha=1e-05,\n",
    "                               seed=42)\n",
    "    \n",
    "        # list of models\n",
    "    list_of_model = {\n",
    "    \"undersampling\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_tuning.__class__.__name__+\"_\"+\"tuning\", \"model_object\": xgb_tuning, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    \"smote\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_tuning.__class__.__name__+\"_\"+\"tuning\", \"model_object\": xgb_tuning, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    }\n",
    "        # training of rus\n",
    "    training_log, list_of_model_rus = train_eval_model(\n",
    "    list_of_model[\"undersampling\"],\n",
    "    \"baseline_model\",\n",
    "    x_rus,\n",
    "    y_rus,\n",
    "    \"undersampling\",\n",
    "    x_test,\n",
    "    y_test,\n",
    "    config[\"training_log_path\"]\n",
    "    )\n",
    "    \n",
    "    list_of_model[\"undersampling\"] = copy.deepcopy(list_of_model_rus)\n",
    "    # list_of_model[\"undersampling\"].append(copy.deepcopy(list_of_model_rus))\n",
    "    \n",
    "       # training of smote\n",
    "    training_log, list_of_model_sm = train_eval_model(\n",
    "    list_of_model[\"smote\"],\n",
    "    \"baseline_model\",\n",
    "    x_sm,\n",
    "    y_sm,\n",
    "    \"smote\",\n",
    "    x_test,\n",
    "    y_test,\n",
    "    config[\"training_log_path\"]\n",
    "    )\n",
    "    \n",
    "    list_of_model[\"smote\"] = copy.deepcopy(list_of_model_sm)\n",
    "    # list_of_model['smote'].append(copy.deepcopy(list_of_model_sm))\n",
    "    \n",
    "    # log to df\n",
    "    training_res = training_log_to_df(training_log)\n",
    "    \n",
    "    # get best model\n",
    "    model = get_best_model(training_res, list_of_model)\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    # save best model\n",
    "    dump_pickle(model, config[\"production_model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "939551f3-ce0d-4172-a80d-72394fc954d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,10):\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0b3fd-9d79-4f75-8d73-34b141b02623",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09f760-29cf-46f0-8b15-8de22a92a5f3",
   "metadata": {},
   "source": [
    "# 4. MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "b72731cb-93f2-426c-8763-95fe743418b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_collection\n",
    "# import praprocessing\n",
    "# import modelling\n",
    "from sklearn.metrics import classification_report,\n",
    "import pandas as pd\n",
    "\n",
    "# from utils import load_config, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "8225dc51-2cf3-4f89-aebb-c482cc897543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    data_collections.main()\n",
    "\n",
    "    data_preprocessing.main()\n",
    "\n",
    "    modelling.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "6da6c547-fac8-43b0-96d2-15a55b5e8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config = load_config()\n",
    "\n",
    "    # train()\n",
    "\n",
    "    model = load_pickle(config[\"production_model_path\"])\n",
    "    \n",
    "    x_train = load_pickle(config[\"prep_sm_path\"][\"x_sm\"])\n",
    "    y_train = load_pickle(config[\"prep_sm_path\"][\"y_sm\"])\n",
    "\n",
    "    x_test = load_pickle(config[\"prep_test_path\"][\"x_test\"])\n",
    "    y_test = load_pickle(config[\"prep_test_path\"][\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "7c27c499-336b-4b42-aa0e-e3395b951397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_testing(model,fitur_train, y_train, fitur_test, y_test):\n",
    "    #test\n",
    "    predY = model.predict(fitur_test)\n",
    "    probs = model.predict_proba(fitur_test)\n",
    "    probs = probs[:, 1]\n",
    "    #classification report\n",
    "    print(\"Testing Report\")\n",
    "    print(classification_report(y_test, predY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "fe618ecc-a760-4ac8-a5f7-20cbd86048b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1100\n",
      "           1       0.61      0.74      0.67        82\n",
      "\n",
      "    accuracy                           0.95      1182\n",
      "   macro avg       0.80      0.85      0.82      1182\n",
      "weighted avg       0.95      0.95      0.95      1182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_testing(model,x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03d5db-8aac-45d4-8316-9ef95ee49fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
